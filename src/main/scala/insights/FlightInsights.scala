package insights

import org.apache.spark.rdd.RDD
import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.sql.functions.{broadcast, col}

import scala.util.Try

object FlightInsights {

  private def masterFile(folder: String) = s"$folder/On_Time_On_Time_Performance_2018_1.csv"
  private def lookupAirlineFile(folder: String) = s"$folder/L_AIRLINE_ID.csv"
  private def lookupCityMarketFile(folder: String) = s"$folder/L_CITY_MARKET_ID.csv"
  private def lookupAirportFile(folder: String) = s"$folder/L_AIRPORT_ID.csv"

  private val numPartitions = 6

  /**
    * Reads master the data into a DataFrame, reads lookup tables into a broadcast variable, and joins all
    * the datasets together.
    * @param folder the source folder where the files can be found.
    * @param spark spark session
    * @return A DataFrame with all the joined data sets.
    */
  def readData(folder: String, spark: SparkSession): DataFrame = {
    import spark.implicits._

    val master = spark
      .read
      .option("header", "true")
      .csv(masterFile(folder))
      .select($"AirlineID", $"DestCityMarketID", $"DestAirportID", $"ArrDelayMinutes".as[Double])
      .na.fill("0.0", Seq("ArrDelayMinutes"))

    val airlines = broadcast(
      spark.read.option("header", "true").csv(lookupAirlineFile(folder))
        .select(
          col("Code").as("AirlineCode"),
          col("Description").as("AirlineName")
        )
    )

    val cityMarkets = broadcast(
      spark.read.option("header", "true").csv(lookupCityMarketFile(folder))
        .select(
          col("Code").as("CityMarketCode"),
          col("Description").as("CityMarketName")
        )
    )

    val airports = broadcast(
      spark.read.option("header", "true").csv(lookupAirportFile(folder))
        .select(
          col("Code").as("AirportCode"),
          col("Description").as("AirportName")
        )
    )

    master
      .join(airlines, master("AirlineID") === airlines("AirlineCode"))
      .join(cityMarkets, master("DestCityMarketID") === cityMarkets("CityMarketCode"))
      .join(airports, master("DestAirportID") === airports("AirportCode"))
  }

  private def safeDouble(v: String): Double = Try(v.toDouble).toOption.getOrElse(0d)

  /**
    * Converts the DataFrame generated by readData() into its RDD equivalent.
    * @param master the master DataFrame
    * @return the same data set as an RDD
    */
  def toRDD(master: DataFrame): RDD[FlightRow] = {
    import master.sparkSession.implicits._
    val ds = master.map { row =>
      FlightRow(
        row.getAs[String]("AirlineID"),
        row.getAs[String]("AirlineName"),
        row.getAs[String]("DestCityMarketID"),
        row.getAs[String]("CityMarketName"),
        row.getAs[String]("DestAirportID"),
        row.getAs[String]("AirportName"),
        safeDouble(row.getAs[String]("ArrDelayMinutes"))
      )
    }

    ds.rdd
  }

  /**
    * b) data set sorted by the airlines least delay on the top.
    * @param spark spark session
    * @param master the master DataFrame
    * @return the airlines that fly to a certain city market, sorted by the ones that have
    */
  def leastDelay(spark: SparkSession, master: DataFrame): DataFrame = {
    import spark.implicits._

    master
      .select($"AirlineID", $"AirlineName", $"ArrDelayMinutes".as[Double])
      .where($"ArrDelayMinutes" > 0)
      .sort($"ArrDelayMinutes")
  }

  /**
    * c) Groups the data set to find which airlines have the most flights to a city, given as a parameter.
    * Assumes that a city can e served by several airports, so using the DestCityMarketID to
    * represent a city.
    * @param spark spark session
    * @param master the master DataFrame
    * @param cityMarketID the city market ID to use as filter
    * @return The DataFrame with the airlines that serve a given city, sorted by the ones that have most flights
    */
  def mostFlightsTo(spark: SparkSession, master: DataFrame, cityMarketID: String): DataFrame = {
    import spark.implicits._

    master
      .select($"AirlineID", $"DestCityMarketID", $"AirlineName")
      .groupBy("DestCityMarketID", "AirlineID", "AirlineName")
      .count()
      .sort($"count".desc)
      .where($"DestCityMarketID" === cityMarketID)
  }

  type Collector = (Int, FlightRow)

  def mostFlightsTo(master: RDD[FlightRow], cityMarketID: String) = {
    def createCollector(f: FlightRow): Collector = (1, f)
    def combiner(collector: Collector, f: FlightRow): Collector = (collector._1 + 1, collector._2)
    def merger(c1: Collector, c2: Collector): Collector = (c1._1 + c2._1, c1._2)

    val grouped = master
      .map(f => (f.destAirportID, f.airlineID) -> f)
      .combineByKey(createCollector, combiner, merger)
    grouped
        .filter(_._1._2 == cityMarketID)
      .sortBy { case (_, (numFlights, _)) => - numFlights}
      .map { case (_, (numFlights, f)) => (f.destAirportName, f.airLineName, numFlights) }
  }

    /**
    * Groups the data set to answer on which airlines arrive the worst on which airport and by what delay.
    * It uses a SortKey case class to define a composed key to be used by the sorting, which is defined
    * in its companion object.
    * @param master the RDD representation of the master data set (joined with the lookups)
    * @return the RDD sorted by which airlines arrive the worst on which airport and by what delay.
    */
  def worstAirlineAirportCombination(master: RDD[FlightRow]): RDD[FlightRow] = {
    master
      .map(f => SortKey(f.destAirportID, f.airlineID, f.arrDelayMinutes) -> f)
      .sortByKey()
      .values
  }

  /**
    * Groups the data set to answer on which airlines arrive the worst on which airport and by what delay.
    * It's the same as above, but it uses the above mechanisms with a variant that defines a custom
    * partitioner to improve the sorting performance.
    * @param master the RDD representation of the master data set (joined with the lookups)
    * @return the RDD sorted by which airlines arrive the worst on which airport and by what delay.
    */
  def worstAirlineAirportCombinationPartitioned(master: RDD[FlightRow]): RDD[FlightRow] = {
    master
      .map(f => SortKey(f.destAirportID, f.airlineID, f.arrDelayMinutes) -> f)
      .repartitionAndSortWithinPartitions(new FlightPartitioner(numPartitions))
      .values
  }
}
